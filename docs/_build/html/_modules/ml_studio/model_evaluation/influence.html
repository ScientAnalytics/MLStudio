
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>ml_studio.model_evaluation.influence &#8212; ML Studio 0.1.0 documentation</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for ml_studio.model_evaluation.influence</h1><div class="highlight"><pre>
<span></span><span class="c1"># =========================================================================== #</span>
<span class="c1">#                             MODEL VALIDATION                                #</span>
<span class="c1"># =========================================================================== #</span>
<span class="c1"># =========================================================================== #</span>
<span class="c1"># Project: Visualate                                                          #</span>
<span class="c1"># Version: 0.1.0                                                              #</span>
<span class="c1"># File: \influence.py                                                         #</span>
<span class="c1"># Python Version: 3.8.0                                                       #</span>
<span class="c1"># ---------------                                                             #</span>
<span class="c1"># Author: John James                                                          #</span>
<span class="c1"># Company: Decision Scients                                                   #</span>
<span class="c1"># Email: jjames@decisionscients.com                                           #</span>
<span class="c1"># ---------------                                                             #</span>
<span class="c1"># Create Date: Thursday November 28th 2019, 4:20:11 pm                        #</span>
<span class="c1"># Last Modified: Thursday November 28th 2019, 4:21:17 pm                      #</span>
<span class="c1"># Modified By: John James (jjames@decisionscients.com)                        #</span>
<span class="c1"># ---------------                                                             #</span>
<span class="c1"># License: Modified BSD                                                       #</span>
<span class="c1"># Copyright (c) 2019 Decision Scients                                         #</span>
<span class="c1"># =========================================================================== #</span>
<span class="sd">&quot;&quot;&quot;Model data influence analysis and diagnostics.&quot;&quot;&quot;</span> 
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">..model_evaluation.validity</span> <span class="k">import</span> <span class="n">standardized_residuals</span>
<span class="kn">from</span> <span class="nn">..model_evaluation.validity</span> <span class="k">import</span> <span class="n">studentized_residuals</span>

<span class="c1"># --------------------------------------------------------------------------- #</span>
<span class="c1">#                           INFLUENCE MEASURES                                #</span>
<span class="c1"># --------------------------------------------------------------------------- #</span>
<div class="viewcode-block" id="leverage"><a class="viewcode-back" href="../../../index.html#ml_studio.model_evaluation.influence.leverage">[docs]</a><span class="k">def</span> <span class="nf">leverage</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes leverage scores for a data set.</span>

<span class="sd">    Leverage is a measure of how much the independent variables of an </span>
<span class="sd">    observation differs from the other observations. The leverage score for</span>
<span class="sd">    the ith osbservation is defined as:</span>

<span class="sd">    .. math:: h_{ii} = </span>

<span class="sd">    the ith diagonal element of the project matrix \\mathbb{H}=X(X^TX)^{-1}X^T,</span>
<span class="sd">    where X is the design matrix whose rows are observations and columns</span>
<span class="sd">    are the independent variables.</span>

<span class="sd">    The diagonal of the projection matrix, commonly known as the hat matrix, </span>
<span class="sd">    is a standardized measure of the distance from the ith observation from</span>
<span class="sd">    the center (or centroid) of the x-space.</span>

<span class="sd">    Points with leverage greater than \\frac{2p}{n}, where p is the number</span>
<span class="sd">    independent variables, including the bias, and n is the number of </span>
<span class="sd">    observations, are considered remote enough from the rest of the </span>
<span class="sd">    data to be designated a leverage point. [2]_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : ndarray or DataFrame of shape n x m</span>
<span class="sd">        A matrix of n instances with m features</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    leverage : ndarray or DataFrame of shape n x 1</span>
<span class="sd">        Contains the leverage scores for each observation.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute Leverage</span>
    <span class="n">leverage</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">leverage</span></div>

<div class="viewcode-block" id="cooks_distance"><a class="viewcode-back" href="../../../index.html#ml_studio.model_evaluation.influence.cooks_distance">[docs]</a><span class="k">def</span> <span class="nf">cooks_distance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Cook&#39;s Distance, a commonly used measure of data point influence.</span>

<span class="sd">    Cook&#39;s Distance is used in least-squares regression analysis to identify </span>
<span class="sd">    influencial data points. Cook&#39;s distance for a given data point is given by:</span>
<span class="sd">    .. math:: \\mathbb{D}_i = \\frac{\\epsilon^2_i}{ps^2}\\big[\\frac{h_{ii}}{(1-h_{ii})^2}][1]_</span>

<span class="sd">    An alternative formulation relates Cooks Distance to studentized</span>
<span class="sd">    residuals. </span>
<span class="sd">    .. math:: \\mathbb{D}_i =\\bigg[\\frac{1}{p}\\frac{n}{n-p}]t_i^2\\frac{h_{ii}}{1-h{ii}}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : Estimator or BaseEstimator</span>
<span class="sd">        ML Studio or Scikit Learn estimator</span>

<span class="sd">    X : ndarray or DataFrame of shape n x m</span>
<span class="sd">        A matrix of n instances with m features</span>

<span class="sd">    y : ndarray or Series of length n</span>
<span class="sd">        An array or series of target or class values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cooks_distance : ndarray or DataFrame of shape n x 1</span>
<span class="sd">        A matrix of cooks distances computed for each observation</span>

<span class="sd">    Reference</span>
<span class="sd">    ---------</span>
<span class="sd">    .. [1]  Wikipedia contributors. (2019, October 24). Cook&#39;s distance. </span>
<span class="sd">            In Wikipedia, The Free Encyclopedia. Retrieved 01:32, </span>
<span class="sd">            November 29, 2019, from </span>
<span class="sd">            https://en.wikipedia.org/w/index.php?title=Cook%27s_distance&amp;oldid=922838890</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute leverage</span>
    <span class="n">hat</span> <span class="o">=</span> <span class="n">leverage</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># Obtain studentized residuals </span>
    <span class="n">standard_resid</span> <span class="o">=</span> <span class="n">standardized_residuals</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Compute Cooks</span>
    <span class="n">cooks_d</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">p</span> <span class="o">*</span> <span class="n">n</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">standard_resid</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hat</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">hat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cooks_d</span></div>

<div class="viewcode-block" id="dffits"><a class="viewcode-back" href="../../../index.html#ml_studio.model_evaluation.influence.dffits">[docs]</a><span class="k">def</span> <span class="nf">dffits</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the difference in fits (DFFITS).</span>

<span class="sd">    The difference in fits for observation i, denoted (\\DFFITS_i), is defined</span>
<span class="sd">    as:</span>
<span class="sd">    .. math:: \\DFFITS_i = \\frac{\\hat{y}_i-\\hat{y}_{(i)}}{\\sqrt{MSE_{(i)}h_{ii}}}.</span>

<span class="sd">    The numerator measures the difference in the predicted response obtained</span>
<span class="sd">    with and without the ith data point. The denominator is the estimated </span>
<span class="sd">    standard deviation of the difference between predicted responses. Hence,</span>
<span class="sd">    the diffeence in fits quantifies the number of standard deviations that </span>
<span class="sd">    the fitted value changes when the ith observation is omitted.</span>

<span class="sd">    An observation is deemed influential if the absolute value of its DFFITS</span>
<span class="sd">    value is greater than:</span>

<span class="sd">    .. math:: 2\\sqrt{\\frac{p+1}{n-p-1}}</span>

<span class="sd">    where n is the number of observations, p is the number of predictors </span>
<span class="sd">    including the bias term.</span>

<span class="sd">    DFFITS is also related to the students residual, and is in fact the latter</span>
<span class="sd">    times </span>
<span class="sd">    </span>
<span class="sd">    .. math:: \\sqrt(\\frac{h_{ii}}{1-h_{ii}})[1]_</span>

<span class="sd">    Observations with DFFITS greater that 2\\sqrt{\\frac{p}{n}}, where p is the </span>
<span class="sd">    number of predictors including the bias and n is the number of observations,</span>
<span class="sd">    should be investigated.[2]_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : Estimator or BaseEstimator</span>
<span class="sd">        ML Studio or Scikit Learn estimator</span>

<span class="sd">    X : ndarray or DataFrame of shape n x m</span>
<span class="sd">        A matrix of n instances with m features</span>

<span class="sd">    y : ndarray or Series of length n</span>
<span class="sd">        An array or series of target or class values </span>

<span class="sd">    References</span>
<span class="sd">    ----------    </span>
<span class="sd">    .. [1] Montogomery, Douglas C.; Peck, Elizabeth A.; Vining, G. </span>
<span class="sd">           Geoffrey (2012). Introduction to Linear Regression Analysis </span>
<span class="sd">           (5th ed.). Wiley. p. 218. ISBN 978-0-470-54281-1. Retrieved </span>
<span class="sd">           22 February 2013. Thus, DFFITSi is the value of R-student </span>
<span class="sd">           multiplied by the leverage of the ith observation [hii/(1-hii)]1/2.</span>
<span class="sd">    .. [2] Belsley, David A.; Kuh, Edwin; Welsh, Roy E. (1980). </span>
<span class="sd">           Regression Diagnostics: Identifying Influential Data and </span>
<span class="sd">           Sources of Collinearity. Wiley Series in Probability </span>
<span class="sd">           and Mathematical Statistics. New York: John Wiley &amp; Sons. </span>
<span class="sd">           pp. 11–16. ISBN 0-471-05856-4.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r_student</span> <span class="o">=</span> <span class="n">studentized_residuals</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">hat</span> <span class="o">=</span> <span class="n">leverage</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">r_student</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">hat</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">hat</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span></div>



</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">ML Studio</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../readme.html">ML Studio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../history.html">History</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, John James.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>